\documentclass[journal,11pt,onecolumn]{IEEEtran}  % Comment this line out if you need a4paper
%\IEEEoverridecommandlockouts                              % This command is only needed if you want to use the \thanks command
%\overrideIEEEmargins                                            % Needed to meet printer requirements.
\input{preamble}

\renewcommand{\baselinestretch}{1.0}
\setlength{\parindent}{20pt}
\parskip=5pt

\title{\LARGE \bf
Pattern Matching in Sub-Linear Time Using a Sparse Fourier Transform Approach
}
\author{\IEEEauthorblockN{Nagaraj T. Janakiraman, Avinash Vem, Krishna R. Narayanan \\}
\IEEEauthorblockA{Department of Electrical \& Comp. Engg., Texas A\&M University, College Station, TX, U.S.A\\}
\{tjnagaraj,vemavinash,krn\}@tamu.edu\\
\thanks{This work was supported by the National Science Foundation under grants}
}
\begin{document}
\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
We consider the problem of querying a string (or, a database) of length $N$ bits to determine all the locations where a substring (query) of length $M$ appears either exactly or is within a Hamming distance of $K$ from the query. We assume that sketches of the original signal can be computed off line and stored. Using the sparse Fourier transform computation based approach introduced by Pawar and Ramchandran, we show that all such matches can be determined with high probability in sub-linear time. Specifically, if the number of matches is $L=N^\lambda$ and $M = N^\mu$, as $N \rightarrow \infty$, we show that the locations can be determined with a probability that approaches 1, with a computational complexity that is only $O\left(\max \left(\frac{N}{M} \log N, M L \log N \right) \right) = O\left(N^{\max(1-\mu,\mu+\lambda)} \log N \right)$ for $K \leq \frac{1}{6}M$. Further, the number of Fourier transform coefficients that need to be computed, stored and accessed, i.e., the sketching complexity of this algorithm is only $O\left( N^{\max(\mu,1-\mu)}\right)$. Several extensions of the main theme are also discussed.
\end{abstract}
\input{Problem_statement}
\input{Notations}
\input{AlgorithmDescription}  
%\input{Performance_Analysis}
\section{Performance Analysis}
\def\vgap{2pt}
In this section, we will analyze the overall probability of error involved in finding the correct matching positions. This can be done by analyzing the following three error events independently and then using a union bound to bound the total probability of error.

\begin{itemize}
	\item $\mathcal{E}_1${-\it Bin Classification}: Event that a bin is wrongly classified
	\item $\mathcal{E}_2${-\it Position Identification}: Given a bin is correctly identified as a singleton, event that the position of singleton is identified incorrectly
	\item $\mathcal{E}_3${-\it Peeling Process}: Given the classification of all the bins and the position identification of singletons in each iteration is accurate, event that the peeling process fails to recover the $L$ significant correlation coefficients
\end{itemize}

\subsection{\bf Bin Classification}
\begin{lemma}
The probability of bin classification error at any bin $(i,j)$ can be upper bounded by
\begin{align*}
\mbb{P}[\mc{E}_1]\leq 6e^{-\frac{N^{\mu-\alpha}(1-6\eta)^2}{16}}
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\mbb{P}[\mc{E}_1]&=\mbb{P}[\msc{H}_z]\mbb{P}[\mc{E}_1|\widehat{\msc{H}}_{i,j}=\msc{H}_z]~+
						\quad \mbb{P}[\msc{H}_s]\mbb{P}[\mc{E}_1|\widehat{\msc{H}}_{i,j}=\msc{H}_s]~+
						\quad\mbb{P}[\msc{H}_d]\mbb{P}[\mc{E}_1|\widehat{\msc{H}}_{i,j}=\msc{H}_d \cup \msc{H}_m]\\
				&\leq \mbb{P}[\mc{E}_1|\widehat{\msc{H}}_{i,j}=\msc{H}_z]~+
						\quad \mbb{P}[\mc{E}_1|\widehat{\msc{H}}_{i,j}=\msc{H}_s]~+
						\quad \mbb{P}[\mc{E}_1|\widehat{\msc{H}}_{i,j}=\msc{H}_d \cup \msc{H}_m]\\
    			&\leq  e^{-\frac{N^{\mu-\alpha}(1-2\eta)^2}{8}}+2e^{-\frac{N^{\mu-\alpha}(1-4\eta)^2}{16}}+ 2e^{-\frac{N^{\mu-\alpha}(1-6\eta)^2}{16}}+e^{-\frac{N^{\mu-\alpha}(1-6\eta)^2}{16}}\\
    			&\leq 6e^{-\frac{N^{\mu-\alpha}(1-6\eta)^2}{16}}\\
						\end{align*}
						where the inequalities in the third line are due to Lemmas \ref{Lem:ZerotonClassif}, \ref{Lem:SingletonClassif}, \ref{Lem:DoubletonClassif} and \ref{Lem:MultitonClassif} respectively provided in Appendix \ref{Append:BinClassif}.
\end{proof}

\subsection{\bf Position Identification}
\begin{lemma}
Given that a bin $(i,j)$ is correctly classified as a singleton, the probability of error in identifying the position of the non-zero variable node can be upper bounded by
\begin{align*}
\mbb{P}[\mc{E}_2|\overline{\mc{E}}_1]\leq e^{-\frac{N^{\mu-\alpha}(1-2\eta)^2}{8}}+e^{-\frac{N^{\mu-\alpha}(1-2\eta)^2}{8}}
\end{align*}
\end{lemma}

\subsection{\bf Peeling Process}
To analyze the peeling process alone independently, we refer to a {\it oracle based peeling decoder} which has the accurate classification of all the bins and can accurately  identify the position of the singleton given a singleton bin at any iteration. In other words, oracle based peeling decoder is the peeling part of our decoding scheme but with the assumption that the bin classification and position identification are carried out without any error.
\begin{lemma}
[Exact Matching]
For the exact matching case, choose $F^{d-1}=\eta N^\alpha$ where $\eta$ is chosen as given in Table. \ref{Table:EtaValues}. Then the oracle based peeling decoder:
\begin{itemize}
\item successfully uncovers all the $L$ matching positions if $L=\Omega(N^{\alpha})$ and $L<N^{\alpha}$, with probability at least $1-O(1/dF)$
\item successfully uncovers all the $L$ matching positions, if $L=o(N^{\alpha})$, with probability at least $1-e^{-\beta \epsilon_1^2k^{1/(4l+1)}}$ for some constants $\beta,\epsilon_1>0$ and $l>0.$
\end{itemize}
\end{lemma}
\begin{proof}
We borrow this result from Pawar and Ramchandran's \cite{pawar2014robust}. Although our RSDIFT framework and their robust-FFAST scheme have three main differences: 
\begin{itemize}
\item We are computing smaller IDFT's to recover a sparse bigger IDFT whereas in \cite{pawar2014robust} the same is true for DFT instead of IDFT
\item In the decoding scheme: Our problem model is such that the sparse components of the signal space has only positive amplitude and thus our bin processing part (bin classification and position identification) is different compared to \cite{pawar2014robust}
\item The sparsity of the signal $L$ to be recovered is exactly known in the case of \cite{pawar2014robust} whereas we have no information  about $L$ not even the order with which the quantity scales in $N$
\end{itemize}
Irrespective of these two differences, the Tanner graph representation of the framework and the peeling part of the decoder are identical to that of the robust-FFAST scheme. And thus the limits of the {\it oracle based peeling decoder} for our scheme, which assumes the bin processing is accurate and thus making the analysis independent of bin decoder, will be identical to that of the peeling part of the decoding scheme in robust-FFAST. With respect to the third difference, we claim that if $L$ is of the same order as $f_i$ and has appropriate constants as in r-FFAST we claim the identical result of polynomial decay of error probability. But in the case of $L=o(N^{\alpha})$ we can recover $1-\epsilon$ fraction of $N^{\alpha}$.... TBC
\end{proof}

In any iteration, given a singleton bin, the peeling process, in the case of approximate matching, runs the Singleton-Decoder algorithm on the bin only if it was either originally a singleton or originally a double-ton with one of the variable nodes being peeled off already. Whereas  in the case of exact matching case, the peeling decoder runs the Singleton-Decoder on the bin irrespective of it's original degree. Hence we need to analyze the oracle based peeling decoder for the approximate matching case differently compared to the exact matching case. 
\begin{lemma}
[Approximate Matching]
The oracle based peeling decoder in the approximate matching case: for $d\geq 8$ and $F=\eta L$ where $\eta$ is chosen as given in Table. \ref{Table:EtaValuesGT}:
\begin{itemize}
\item successfully fails to uncover all but a small fraction $\epsilon=10^{-3}$ of the matching positions, if $L=\Omega(N^{\alpha})$ and $L<N^{\alpha}$ with exponentially decaying probability.
\item successfully uncovers all the $L$ matching positions, if $L=o(N^{\alpha})$, with probability at least $1-e^{-\beta \epsilon_1^2k^{1/(4l+1)}}$ for some constants $\beta,\epsilon_1>0$ and $l>0.$
\end{itemize}
For higher target $\epsilon$, we need to give the higher values of $d$ and $\eta$ according to Group testing paper. But the difficulty is in proving that for which we need the equivalence of the CRT construction with random construction and hence requires careful factorization of $f_1,f_2,\ldots,$.
\end{lemma}
\begin{proof}
First write the two ensembles as defined in and write the equivalence lemma. Then point out that for the balls and bins model it has Poisson distribution. Then point out that for this ensemble it was shown in \cite{lee2015saffron} the singletons and double-tons only peeling decoder is shown to achieve arbitrarily small error floors by increasing $\eta$ and $d$. Q.E.D
\end{proof}

\input{Complexity_Analysis}
\input{Appendices}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{ieeetr}
\bibliography{../bib/journal_abbr,../bib/sparseestimation}
\end{document}