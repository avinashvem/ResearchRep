\section{Performance Analysis}
\label{sec:analysis}
\def\vgap{2pt}
In this section, we will analyze the overall probability of error involved in finding the correct matching positions. This can be done by analyzing the following three error events independently and then using a union bound to bound the total probability of error.

\begin{itemize}
	\item $\mathcal{E}_1${-\it Bin Classification}: Event that a bin is wrongly classified
	\item $\mathcal{E}_2${-\it Position Identification}: Given a bin is correctly identified as a singleton, event that the position of singleton is identified incorrectly
	\item $\mathcal{E}_3${-\it Peeling Process}: Given the classification of all the bins and the position identification of singletons in each iteration is accurate, event that the peeling process fails to recover the $L$ significant correlation coefficients
\end{itemize}

\subsection{\bf Bin Classification}
\begin{lemma}
The probability of bin classification error at any bin $(i,j)$ can be upper bounded by
\begin{align*}
\mbb{P}[\mc{E}_1]\leq 6e^{-\frac{N^{\mu+\alpha-1}(1-6\eta)^2}{16}}
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\mbb{P}[\mc{E}_1]&=\mbb{P}[\msc{H}_z]\mbb{P}[\mc{E}_1|\widehat{\msc{H}}_{i,j}=\msc{H}_z]~+
						\quad \mbb{P}[\msc{H}_s]\mbb{P}[\mc{E}_1|\widehat{\msc{H}}_{i,j}=\msc{H}_s]~+
						\quad\mbb{P}[\msc{H}_d]\mbb{P}[\mc{E}_1|\widehat{\msc{H}}_{i,j}=\msc{H}_d \cup \msc{H}_m]\\
				&\leq \mbb{P}[\mc{E}_1|\widehat{\msc{H}}_{i,j}=\msc{H}_z]~+
						\quad \mbb{P}[\mc{E}_1|\widehat{\msc{H}}_{i,j}=\msc{H}_s]~+
						\quad \mbb{P}[\mc{E}_1|\widehat{\msc{H}}_{i,j}=\msc{H}_d \cup \msc{H}_m]\\
    			&\leq  e^{-\frac{N^{\mu-\alpha}(1-2\eta)^2}{8}}+2e^{-\frac{N^{\mu-\alpha}(1-4\eta)^2}{16}}+ 2e^{-\frac{N^{\mu+\alpha-1}(1-6\eta)^2}{16}}+e^{-\frac{N^{\mu+\alpha-1}(1-6\eta)^2}{16}}\\
    			&\leq 6e^{-\frac{N^{\mu+\alpha-1}(1-6\eta)^2}{16}}\\
						\end{align*}
						where the inequalities in the third line are due to Lemmas \ref{Lem:ZerotonClassif}, \ref{Lem:SingletonClassif}, \ref{Lem:DoubletonClassif} and \ref{Lem:MultitonClassif} respectively provided in Appendix \ref{Append:BinClassif}.
\end{proof}

\subsection{\bf Position Identification}
\begin{lemma}
Given that a bin $(i,j)$ is correctly classified as a singleton, the probability of error in identifying the position of the non-zero variable node can be upper bounded by
\begin{align*}
\mbb{P}[\mc{E}_2|\overline{\mc{E}}_1]\leq \exp\left\lbrace-\frac{N^{\mu+\alpha-1}(1-2\eta)^2(c_1^2-1)}{8(c_1^2+1)}\right\rbrace + \exp\left\lbrace-\frac{N^{\mu+\alpha-1} ~ (c_1(1 - 2\eta) - 1)^2}{8(1+ c_1^2)}\right\rbrace
\end{align*}
\end{lemma}
\begin{proof}
	The detailed proof is provided in Appendix \ref{Append:PositionIdentif}.
\end{proof}

\subsection{\bf Peeling Process}
\begin{table}[h]
\centering
\begin{tabular}{| c | c | c | c | c | c | c | c | c | }
\hline
$d$ & $2$& $3$ & $4$ & $5$ & $6$ & $7$ & $8$ & $9$ \\ \hline
$\eta$ & 1.000 & 0.4073 & 0.3237 & 0.2850 & 0.2616 & 0.2456 & 0.2336 & 0.2244 \\ \hline
 $d\eta$ & 2.000 & 1.2219 & 1.2948 & 1.4250 & 1.5696 & 1.7192 & 1.8688 & 2.0196 \\ \hline
\end{tabular}
\vspace{1ex}
\caption{Constants for various error floor values}
\label{Table:EtaValues}
\end{table}

To analyze the peeling process alone independently, we refer to a {\it oracle based peeling decoder} which has the accurate classification of all the bins and can accurately  identify the position of the singleton given a singleton bin at any iteration. In other words, oracle based peeling decoder is the peeling part of our decoding scheme but with the assumption that the bin classification and position identification are carried out without any error.
\begin{lemma}
[Exact Matching]
For the exact matching case, choose $F^{d-1}=\eta N^\alpha$ where $\eta$ is chosen as given in Table. \ref{Table:EtaValues}. Then the oracle based peeling decoder:
\begin{itemize}
\item successfully uncovers all the $L$ matching positions if $L=\Omega(N^{\alpha})$ and $L\leq N^{\alpha}$, with probability at least $1-O(1/N^{\frac{1}{d}})$
\item successfully uncovers all the $L$ matching positions, if $L=o(N^{\alpha})$, with probability at least $1-e^{-\beta \varepsilon_1^2N^{\alpha/(4l+1)}}$ for some constants $\beta,\varepsilon_1>0$ and $l>0.$
\end{itemize}
\end{lemma}
\begin{proof}
We borrow this result from Pawar and Ramchandran's \cite{pawar2014robust}. Although our RSDIFT framework and their robust-FFAST scheme have three main differences: 
\begin{itemize}
\item We are computing smaller IDFT's to recover a sparse bigger IDFT whereas in \cite{pawar2014robust} the same is true for DFT instead of IDFT
\item In the decoding scheme: Our problem model is such that the sparse components of the signal space has only positive amplitude and thus our bin processing part (bin classification and position identification) is different when compared to \cite{pawar2014robust}
\item The sparsity of the signal $L$ to be recovered is exactly known in the case of \cite{pawar2014robust} whereas we have no information  about $L$ not even the order with which the quantity scales in $N$
\end{itemize}
Irrespective of these two differences, the Tanner graph representation of the framework and the peeling part of the decoder are identical to that of the robust-FFAST scheme. And thus the limits of the {\it oracle based peeling decoder} for our scheme, which assumes the bin processing is accurate thus making the peeling decoder analysis independent of the bin decoder and hence will be identical to that of the peeling part of the decoding scheme in robust-FFAST. With respect to the third difference, in robust-FFAST scheme the authors choose $F^{d-1}=\eta k$ where $k$ is the sparsity of the signal (which is assumed to be known) and show the first assertion of the lemma. And it was also shown that upto a constant fraction $(1-\varepsilon)$ of $k$-variables node can be recovered with exponential probability. But in our framework, if $L=o(N^{\alpha})$, then this result translates to recovering all the $L$ non-zero variable nodes with an exponentially decaying failure  probability.
\end{proof}

In any iteration, given a singleton bin, the peeling process, in the case of approximate matching, runs the Singleton-Decoder algorithm on the bin only if it was either originally a singleton or originally a double-ton with one of the variable nodes being peeled off already. This is in contrast to the exact matching case where the peeling decoder runs the Singleton-Decoder on the bin irrespective of it's original degree. Hence we need to analyze the oracle based peeling decoder for the approximate matching case separately compared to the exact matching case. 
\begin{lemma}
[Approximate Matching]
For the approximate matching case, choose parameter $d\geq 8$ as described in Sec. \ref{subsec:DesignParameters} and $F^{d-1}=0.7663 N^{\alpha}$. Then the oracle based peeling decoder: %where $\eta$ is chosen as given in Table. \ref{Table:EtaValuesGT}:
\begin{itemize}
\item successfully uncovers all but a small fraction $\varepsilon=10^{-3}$ of the $L$ matching positions, if $L=\Omega(N^{\alpha})$ and $L\leq N^{\alpha}$ with exponentially decaying failure probability
\item successfully uncovers all the $L$ matching positions, if $L=o(N^{\alpha})$, with probability at least $1-e^{-\beta \varepsilon_1^2N^{\alpha/(4l+1)}}$ for some constants $\beta,\varepsilon_1>0$ and $l>0.$
\end{itemize}
%For higher target $\varepsilon$, we need to give the higher values of $d$ and $\eta$ according to Group testing paper. But the difficulty is in proving that for which we need the equivalence of the CRT construction with random construction and hence requires careful factorization of $f_1,f_2,\ldots,$.
\end{lemma}
\begin{proof}
As mentioned earlier the key difference in the approximate matching case is peeling off variable nodes from only singleton and double-tons. An identical peeling decoder is used and analyzed in the problem of group testing \cite{lee2015saffron} by Lee, Pedarsani and Ramchandran which the authors refer to as SAFFRON scheme. In SAFFRON the authors claim that for a graph ensemble which has a regular degree of $d$ on the variable nodes and a  Poisson degree distribution on the bins, this peeling decoder with a left degree of $d=8$ and a total number of bins atleast equal to $6.13 k$ recovers atleast $(1-\varepsilon)$ fraction of the $k$ non-zero variable nodes with exponentially decaying probability. Note that $\frac{6.13}{8}\approx 0.7663$ is approximately the number of bins per stage for $d=8$. We also leverage the result from \cite{pawar2014robust} that the Tanner graph representation of the robust-FFAST (or equivaently RSDIFT framework) has a Poisson degree distribution on the bins. Combining these two results gives us the required results.
\end{proof}

\begin{comment}
\begin{theorem}[Overall Probability of Error ($P_e$)]
	For the system parameters chosen according to Sec. \ref{subsec:DesignParameters}, the RSIDFT framework
	{\it Exact Matching:}\begin{itemize}
		\item[-] succe
	\end{itemize}
\end{theorem}
\begin{proof}
\end{proof}
\end{comment}
