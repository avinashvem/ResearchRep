\section{Introduction and Problem Statement}
\label{sec:introduction}
We consider the substring/pattern matching problem, which has been studied extensively in theoretical computer science.
In this problem, a signal $\xv \coleq (x[0], x[1], \ldots, x[N-1])$ of length $N$ symbols representing a string, library, or database is available.
The objective is to answer queries regarding whether a given string $\yv \coleq (y[0], y[1],\ldots, y[M-1])$ of length $M$ is a substring of $\xv$.
We are especially interested in the case where a sketch of $\xv$ can be computed offline and stored, and where the one-time computational complexity of creating the sketch can be amortized over repeated queries or ignored.
Moreover, we focus on the random setting in which the $x[i]$'s form a sequence of independent and identically distributed (i.i.d.) random variables, each taking value in $\mathcal{A} \subset \mathbb{R}$. We begin our analysis by restricting our attention to the binary case where $\mathcal{A} \coleq \{\pm 1\}$.\footnote{Extensions to other alphabets $\mathcal{A} \subset \mathbb{R}$ are straightforward. Extension to the non-i.i.d.\ case is also possible.}
Within this context, we consider the following two settings:

{\bf Exact Pattern Matching:} In the exact pattern matching problem, a substring of length $M$ of $\xv$, namely $\yv \coleq \xv[\tau:\tau+M-1]$, is obtained by taking $M$ consecutive symbols from $\xv$ and is presented as a query. This pattern may appear within $\xv$ in up to $L$ different locations $\tau_1, \tau_2, \ldots, \tau_L$ and the task is to determine all the locations $\tau_i, \forall i\in[1:L]$.
We consider the probabilistic version where our objective is to recover the matching locations with a probability that approaches 1 as $M,N \rightarrow \infty$.

{\bf Approximate Pattern Matching:} In approximate pattern matching, $\yv$ is a noisy version of a substring, i.e., $\yv = \xv[\tau:\tau+L-1] \odot \bv$, where $\bv$ is a noise sequence with $b[i] \in \{ \pm 1 \}$ such that $d_H(\yv,\xv[\tau:\tau+M-1]) \leq K$.
Function $d_H$ denotes the Hamming distance, and $\odot$ represents component-wise multiplication. The objective is to determine all locations $\tau_i$ such that $d_H(\yv,\xv[\tau_i:\tau_i+M-1]) \leq K$ with a probability that approaches 1 as $K, M$ and $N \rightarrow \infty$.

Broadly speaking, these problems are relevant to many applications including text matching, audio/image matching, DNA matching in genomics, metabolomics, etc., searching for signatures of events within large databases. The proposed techniques are particularly relevant now due to the interest in applications involving huge volumes of data. Our proposed approach is most useful in the following situations.
(i) The string $\xv$ is available before querying and one time computations such as computing a sketch of $\xv$ can be performed offline and stored, and the complexity of computing the sketch of $\xv$ can be ignored. Then, when queries in the form of $\yv$ appear, one would like to decrease the computational complexity in searching for the string $\yv$. (ii) The string $\xv$ is not centrally available, but parts of the string are sensed by different data collecting nodes distributively and communicated to a central server. A search query is presented to the server; and this server must decide whether the string appears in the data sensed by one or more of the distributed nodes and, if present, it must also identify when the queried string appeared.
In this latter case, we with to minimize the amount of data communicated by the nodes to the server and the computational complexity in searching for the string.
The proposed formulation is most useful when the query $\yv$ is not a pattern that can be predicted and, therefore, creating a lookup table to quickly identify commonly-occurring patterns will not be effective.
%For e.g., $\xv$ is an i.i.d sequence of $\pm 1$ and $\yv$ could be a substring of $\xv$.

A naive approach to searching for substring $\yv$ in $\xv$ is to first compute the cross-correlation between $\xv$ and $\yv$, which we denoted by $\rv=[r[0], r[1],\ldots, r[N-1]]$ with
\begin{align}
\label{Eqn:DefCrossCorrelation}
r[m]=(\xv*\yv)[m] \defeq \sum_{i=1}^{M} x[m+i-1] y[i] ,
\end{align}
and, subsequently,  choosing the index $m$ that maximizes $r[m]$.
This strategy uses the $N$ samples of $\xv$ and has a super-linear computational complexity of $MN = O(N^{1+\mu})$. A computationally more efficient approach uses the fact that $\rv$ can be computed by taking the inverse Fourier transform of the product of the Fourier transforms of $\xv$ and $ \yv^*[-n]$, where $\yv^*[-n]$ is the conjugate of the time reversed version of $\yv$.
Such an approach still uses all the $N$ samples of $\xv$, but reduces the computational complexity to $O(N \log N)$. Note that even though the Fourier transform of $\xv$ can be precomputed, the $N$-point Fourier transform of $\yv$ still needs to be computed online resulting in the $O(N \log N)$ computational complexity.

Both the exact pattern matching problem and the approximate pattern matching problem have been extensively studied in computer science.
Three recent articles \cite{andoni2013shift}, \cite{amir2004faster} and \cite{navarro2001guided} provide a brief summary of existing contributions.
For the exact matching problem, the Rabin-Karp algorithm solves a more general problem of finding the occurrence of a set of query strings.
However, the algorithm has a computational complexity that is at least linear in $N$. Boyer and Moore presented an algorithm in \cite{boyer1977fast} for finding the first occurrence of the match (only $\tau_1$) that has an expected complexity of $O(N/M \log N) = O(N^{1-\mu} \log N)$, whereas the worst case complexity (depending on $\tau_1$'s) can be $O(N \log N)$. For large $M$, the algorithm indeed has an average complexity that is sub-linear in $N$. More recently, it has been shown that techniques based on the Burrows-Wheeler transform can be used to solve the exact matching problem with sub-linear time complexity \cite{ferragina2005indexing} and has been well studied under the read alignment setting by the Bioinformatics community \cite{li2009fast,li2010fast}. For small $|\mathcal{A}|$, it has the best known complexity; however, the complexity increases with $|\mathcal{A}|$. Further, extensions to approximate matching setting \cite{zhang2003approximate} has a complexity that increases exponentially in $K$ and, hence, appear to be infeasible for $K = O(M)$. The Boyer and Moore algorithm has been generalized to the approximate pattern matching problem in \cite{chang1994approximate} with an average case complexity of $O(NK/M \log N)$, which provides a sub-linear time algorithm only when $K \ll M$. In \cite{andoni2013shift}, Andoni, Hassanieh, Indyk and Katabi have given the first sub-linear time algorithm with a complexity of $O(N/M^{0.359})$ for $K = O(M)$.

\section{Our Main Results and Relation to Prior Work}
\label{sec:mainresults}
The following theorem summarizes our main results in this work.

\begin{theorem}\label{thm:mainresults}
Assume that a sketch of $\xv$ of size $O(\frac{N}{M} \log N)$ can be computed and stored. Then for the {\it exact pattern matching} and {\it approximate pattern matching} (with $K = \eta M$) problems, with the number of matches $L$ scaling as $O(N^{\lambda})$, our algorithm has
\begin{itemize}
 \item a sketching function for $\yv$ that computes \\ $O(\frac{N}{M}\log N)~=~ O\left(N^{1-\mu}\log N\right)$ samples
  \item a computational complexity of \\$O\left(\max\{N^{1-\mu}\log^2 N, N^{\mu+\lambda}\log N \}\right)$
  \item a decoder that recovers all the $L$ matching positions with a failure probability that approaches zero asymptotically in $N$
  
 \end{itemize}
%Particularly when we are interested only in finding a constant number of matches $L=O(1)$ or $L<\frac{N}{M}$ (i.e. $\lambda<1-\mu$) which is the extreme case of input string $\xv$ being just the repetition of the query $\yv$, which are both very practical assumptions to make for many real world problems, our algorithm has a {\it sub-linear time complexity}.
When $L<O\left(\frac{N}{M}\right)$ (i.e. $\lambda<1-\mu$), which is typically the interesting case, our algorithm has a {\it sub-linear time complexity}.
\end{theorem}
\begin{proof}
We present the error performance analysis of our scheme and the proof of decaying error probability in Sec.~\ref{sec:analysis} after we describe our scheme and  decoding algorithm in Sec.~\ref{sec:Algo_desc}. In Sec.~\ref{Sec:Complexity} we present the sample and computational complexity analyses.
\end{proof}
Our paper is inspired by and builds on two recent works by Hassanieh {\em {et al.}} in \cite{hassanieh2012faster} and Pawar and Ramchandran \cite{pawar2014robust}. In \cite{hassanieh2012faster}, Hassanieh \emph{et al.}, considered the correlation function computation problem for a Global Positioning System (GPS) receiver and exploited the fact that the cross-correlation vector $\rv$ is a very sparse signal in the time domain and, hence, the Fourier transform of $\rv$ need not be evaluated at all the $N$ points. In the GPS application, which was the focus of \cite{hassanieh2012faster}, the query $\yv$ corresponds to the received signal from the satellites and, hence, the length of the query was at least $N$. As a result, the computational complexity is still $O(N \log N)$ (still linear in $N$) and only the constants were improved in relation to the approach of computing the entire Fourier transform. In a later paper by Andoni {\em et al.,} \cite{andoni2013shift}, a sub-linear time algorithm for shift finding in GPS is presented; however, this algorithm is completely combinatorial and eschews algebraic techniques such as FFT-based techniques.

There are important differences between our paper and \cite{hassanieh2012faster,andoni2013shift,boyer1977fast,amir2004faster}. First and foremost, the algorithms used for pattern matching are entirely different. While their algorithms are combinatorial in nature, our algorithm is algebraic and uses signal processing and coding theoretic primitives. Secondly, the system model considered in our paper differs from the model in \cite{hassanieh2012faster,andoni2013shift,boyer1977fast,amir2004faster} in that we allow for preprocessing or creating a sketch of the data $\xv$. Our algorithm exploits this fact and results in a computational complexity $O(N/M)$ which is better than that in \cite{andoni2013shift} for the approximate pattern matching problem.  Finally, we also consider the problem of finding all matches of the pattern $\yv$ instead of looking for only one match. In \cite{pawar2014robust}, Pawar and Ramchandran present an algorithm based on aliasing and the peeling decoder for computing the Fourier transform of a signal with noisy observations for the case when the Fourier transform is known to be sparse. This algorithm has a complexity of $O(N \log N)$ and they do not consider the pattern matching problem. Our algorithm is similar to that of Pawar and Ramchandran's algorithm with one very important distinction. We modify their algorithm to exploit the fact that the peak of the correlation function of interest is always positive. This modification is key in computing the Sparse Inverse Discrete Fourier Transform (SIDFT) with sub-linear time complexity of $O(N^{1-\alpha} \log N)$, $0 < \alpha \leq 1$ . Thus, one of the main contributions of this paper is to show that signal processing and coding theoretic primitives, i.e., Pawar and Ramchandran's algorithm with some modifications can be used to solve the pattern matching algorithm in sub-linear time. 
