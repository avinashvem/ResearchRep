
 \begin{frame}\frametitle{Problem Statement}
 	\vspace{-0.4cm}
	\begin{figure}[t]
		\centering
		\includegraphics[width=2.8in]{Pattern_matching_ex.jpg}
	\end{figure}
	\vspace{-10pt}
	\begin{block}{}
\begin{itemize}\itemsep5pt
	\item {\color{blue} Database/String}: $\xv = [x[0], x[1], \cdots, x[N-1]]$ \ (length $N$)
	\item { \color{blue} Query/Substring}: $\yv = [y[0], y[1], \cdots, y[M-1]]$ \ (length $M = N^\mu$)
	\item {\color{blue} Signal Model:} $x[i]$'s are i.i.d ~ r.v. from $\mathcal{A} = \{+1,-1\}$ (extensions possible)
\end{itemize}
\end{block}

\vspace{-3pt}
\pause
\begin{block}{}
Determine all the {\color{blue} $L$ locations} $\underline{\tau} = [\tau_1, \tau_2, \cdots \tau_L]$ with  {\color{blue}high probability}  where
	\begin{enumerate}
		\item \alert{Exact Matching}:~  $\yv$ appears {\color{blue}exactly} in $\xv$
		\begin{itemize}
				\item [-]  $\yv := \xv[\tau:\tau+M-1]$
		\end{itemize}
        \pause
		\item \alert{Approximate Matching:} ~ $\yv$ is a {\color{blue}noisy substring} of $\xv$
		\begin{itemize}\itemsep3pt
				\item [-] $\yv := \xv[\tau:\tau+M-1] \odot \bv$
				\item [-] $\bv$ is a noise sequence with $d_H(\yv,\xv[\tau:\tau+M-1]) \leq K$
		\end{itemize}
	\end{enumerate}

	\end{block}
	 \end{frame}
% ----------------------------------------Notations---------------------------------------

\begin{frame}\frametitle{Notation}

	\begin{figure}[t]
		\centering
		\includegraphics[width=2.5in]{Pattern_matching_ex.jpg}
	\end{figure}
	\vspace{-8pt}
	{\small
	\begin{table}[h!]
		\label{Table:Notations3}
		\begin{center}
			\begin{tabular}{|c|c|} 	
				\hline		
				\textit{Symbol}		&  \textit{Meaning} \\		
				\hline
				$N$           		& Size of the string or database in symbols \\
				\hline
				$M = N^{\mu}$       & Length of the query in symbols \\
				\hline
				$L = N^\lambda$    &   Number of matches \\
				\hline
				$K$             &$\max_{\tau}d_{H}(\xv[\tau:\tau+M-1],\yv)$\\
				\hline
				$\eta$             &$\frac{K}{M}$\\
				\hline
				%$G = N^\gamma$    & Number of blocks \\
				%\hline
				%$\tilde{N} = N^{1-\gamma}$   & Length of one block \\
				%\hline
				%$f_i = N^\alpha$     & Length of smaller point IDFT at each branch\\
				%\hline
				%$g_i = N/f_i$     	   &  Sub-sampling parameter \\
				%\hline
				%$B$   					    & Number of shifts also referred to as branches  \\
				%\hline
				%$d$           				& Number of stages in the FFAST algorithm \\
				%\hline
			\end{tabular}
		\end{center}
	\end{table}
    }
    \begin{block}{Probabilistic recovery}
    $\mbb{P}(\hat{\underline{\tau}} \neq \underline{\tau}) \rightarrow 0$ as $N \rightarrow \infty$
    \end{block}
	\end{frame}	
	
%--------------------------------------------- Main Result -------------------------------	
	 \begin{frame} \frametitle{Main Result}

	{\small
	\begin{table}[h!]
		\begin{center}
			\begin{tabular}{|c|c|} 	
				\hline		
				\textit{Symbol}		&  \textit{Meaning} \\		
				\hline
				$N$           		& Size of the string or database in symbols \\
				\hline
				$M = N^{\mu}$       & Length of the query in symbols \\
				\hline
				$L = N^\lambda$    &   Number of matches \\
				\hline
				$K$             &$\max_{\tau}d_{H}(\xv[\tau:\tau+M-1],\yv)$\\
				\hline
				$\eta$             &$\frac{K}{M}$\\
				\hline
			\end{tabular}
		\end{center}
	\end{table}
    }	
     	
    \vspace{-2.5mm}
	 \begin{theorem}
	 	Assume that a sketch of $\xv$ can be precomputed and stored. Then for the {\it exact pattern matching} and {\it approximate pattern matching} (with $K = \eta M,~ 0 \leq \eta \leq 1/6$) problems, our algorithm has
	 	\begin{itemize}
	 		\item \alert{Sketching complexity:} {\color{blue} $O(\frac{N}{M}\log N)=O(N^{1-\mu}\log N)$} \alert{samples}
	 		\item \alert{Computational complexity:}
	 		{\color{blue}$O(\max(N^{1-\mu}\log^2 N, N^{\mu+\lambda}\log N ))$}	 		
	 		\item a decoder for which $\mbb{P}(\hat{{\mathcal{T}}} \neq \mathcal{T}) \rightarrow 0$ as $N \rightarrow \infty$
	 	\end{itemize}
	 \end{theorem}
	 \pause
	 \vspace{-0.5mm}
	 \begin{block}{\alert{Note}}
	 	When $L<\frac{N}{M}$ (i.e. $\lambda<1-\mu$) our algorithm has a {\color{blue}sub-linear time} complexity.
	 \end{block}	
\end{frame}


\begin{frame} \frametitle{Some Prior Work}
	\vspace{-0.2cm}
	 \only<1>{\begin{block}{\alert{Exact Matching}}
	 	
	 	\begin{itemize}
	 		\item  {\color{blue} \bf Boyer'77}: First occurrence of the match (only $\tau_1$)	 		
	 		\begin{itemize}
	 			\item[-] Average complexity - $O(N^{1-\mu} \log N)$ (sublinear)
	 			\item[-] Worst case complexity - $O(N \log N)$
	 		\end{itemize}
	 		\item  {\color{blue}\bf Goodrich'05}: BWT, suffix-arrays based indexing
	 		\begin{itemize}
	 			\item[-] Time complexity - $O(M + L)$ (sublinear)
	 			\item[-] Storage Complexity - $O(N~H_k(X) \log^\epsilon N) + o(N)$ bits  (linear)
	 			\item[-] Read alignment in Bio-informatics community[ {\color{blue}Li'09,Li'10}]
	 		\end{itemize}	 		
	 	\end{itemize}
	 \end{block}
	\begin{block}{\alert{Approximate Matching}}
		
	 	\begin{itemize}
	 		\item {\color{blue} \bf Chang'94}: Generalization of Boyer'77
	 		\begin{itemize}
	 			\item[-] Average time complexity - $O(NK/M \log N)$ (sub-linear only when $K \ll M$ )
	 		\end{itemize}
	 		
	 			\item {\color{blue} \bf Zhang'03}: Approximate Matching using BWT
	 			\begin{itemize}
	 				\item[-] Worst case time complexity: $O(\min\{M(M-K){|\mc{A}|}^k\log \frac{N}{|\mc{A}|} , NM \log \frac{N}{|\mc{A}|}\})$
	 				\item[-] Complexity grows with $|\mc{A}|$ and $K$
	 			\end{itemize}
	 			
	 		\item {\color{blue} \bf Andoni'13}: $O(N/M^{0.359})$ (sub-linear even when $K = O(M)$)
	 		\begin{itemize}
	 			\item[-] Combinatorial in nature
	 		\end{itemize}
	 	\end{itemize}
	 	
	 \end{block}
}
\end{frame}


	
%-------------------------------------------------------------------------------------------------------------
\begin{frame}\frametitle{Motivation}
	\vspace{-0.4cm}
			\begin{block}{}
			
				\begin{itemize}
					\item {\bf Cross-correlation} ($\rv$):
					
					\begin{equation}\label{eqn:Rxy_def} \nonumber
					r[m]=(\xv*\yv)[m] \defeq \sum_{i=0}^{M-1} x[m+i] y[i], ~ ~ \ 0 \leq m \leq N-1
					\end{equation}
					\item {\bf Naive implementation}: $O(MN) = O(N^{1+\mu})$ ({\color{blue} super-linear} complexity)
					\item 	{\bf Fourier Transform Approach}: $O(N \log N)$ complexity
					\begin{equation}\nonumber
					\rv = \mathcal{F}_{N}^{-1} \{~  \mathcal{F}_{N}\{\xv\} ~ \odot ~  \mathcal{F}_{N}\{\yv'\} ~ \}, \ \ \yv' = \yv^{*}[-n]
					\end{equation}
					
				\end{itemize}
			\end{block}
			
				\begin{columns}
					\column{0.45\columnwidth}
			\begin{block}{\alert{ \bf Key Observation}}
			\vspace{0.2cm}
				\begin{itemize}
					\item $\rv$ is {\color{blue}Sparse} with some noise.
				\end{itemize}
				 \begin{equation} \label{eqn:RXY_sparse}\nonumber
				 r[m] \ = \left\{
				 \begin{array}{ll}
				 &M,~~  \text{if} \ m \in \mathcal{T} \\
				 & n_m,~~ m \in [N]-\mathcal{T}
				 \end{array}
				 \right.  			
				 \end{equation}
			\end{block}
						
					\column[]{0.45\columnwidth}
					\begin{figure}
						\centering
						\scalebox{0.35}{\input{cross_corr.tex}}
					\end{figure}
					
				\end{columns}
				
					
\end{frame}
%--------------------------------------------------------------------------------------
\def\fracty{0.45}
\def\fractx{0.8}
\begin{frame}{Example}
	%	\begin{figure}[t]
	%		\centering
	%		\includegraphics[width=4.8in]{Example_full_framework}
	%	\end{figure}
	
	\begin{figure}[t]
		\centering
		\includegraphics[width=4.8in]{Example_full_framework}
	\end{figure}
	
	%\begin{columns}
	%\vspace{-2.0in}
	%\begin{column}{0.48\textwidth}
	%%	Signal Domain
	%\begin{figure}
	%\centering
	%%\text{$x[n]:$}
	%%\resizebox{\fractx\columnwidth}{\fracty\columnwidth}{\input{\fig_path/database_x.tex}}
	%\input{\fig_path/database_x.tex}
	%\end{figure}
	%\vspace{-0.2in}
	%
	%\begin{figure}
	%\centering
	%%\resizebox{\fractx\columnwidth}{\fracty\columnwidth}{\input{\fig_path/query_y.tex}}
	%\input{\fig_path/query_y.tex}
	%\end{figure}
	%
	%\vspace{-0.2in}
	%
	%\begin{figure}
	%\centering
	%%\resizebox{\fractx\columnwidth}{\fracty\columnwidth}{\input{\fig_path/corr_est.tex}}
	%\input{\fig_path/corr_est.tex}
	%\end{figure}
	%\end{column}
	%
	%%\begin{column}{0.48\textwidth}
	%%\tiny{Fourier Domain ($N$-pt FFT)}
	%%\begin{figure}
	%%\centering
	%%\resizebox{0.7\columnwidth}{!}{\input{\fig_path/database_sketch.tex}}
	%%\end{figure}
	%%
	%%\begin{figure}
	%%\centering
	%%\resizebox{0.7\columnwidth}{!}{\input{\fig_path/query_sketch.tex}}
	%%\end{figure}
	%%
	%%\begin{figure}
	%%\centering
	%%\resizebox{0.7\columnwidth}{!}{\input{\fig_path/corr_fft.tex}}
	%%\end{figure}
	%%\end{column}
	%
	%\end{columns}
\end{frame}
%-----------------------------------------
\begin{frame}\frametitle{Sparse Fourier Transform Approach}
        \begin{block}{Robust Sparse Fourier Transform - Pawar and Ramchandran'14}
	 		\begin{itemize}
	 			\item[-] Sparse graph code approach
	 			\item[-] Computational complexity : $O(N \log N)$
	 		\end{itemize}
	 	\end{block}
        \begin{block}{Faster GPS receiver - Hassanieh '12}
	 		\begin{itemize}
	 			\item[-] Exploited sparsity in Correlation function $R_{XY}$
                \item[-] Algorithm based on hashing
                \item[-] In this application, complexity is still $O(N \log N)$
	 		\end{itemize}		
	 	\end{block}	 	

\end{frame}
%---------------------------------------------------------
\begin{frame}\frametitle{Sparse Fourier Transform Approach}
	\begin{figure}[t]
		\centering
		\scalebox{0.28}{\input{notional_diag.tex}}
	\end{figure}
\vspace{-0.2cm}
	 	\begin{block}{}
	 		\begin{equation}\label{eqn:Rxy_fourier}\nonumber
	 		\boxed{\rv = \underset{\text{\color{red} 3 } } {\mathcal{F}_{N}^{-1}} \ \{ \underset{\text{ \color{red} 1 } }{  \mathcal{F}_{N}\{\xv\}}  \odot \ \underset{\text{ \color{red} 2 } }{ \mathcal{F}_{N}\{\yv'\}}  \} }
	 		\end{equation}
	 		
	 		\begin{itemize}
	 			\item[\color{red} 1.] \textit{\color{blue} Sketch of $\xv$ : }  Assume $ \Xv[l] = \mathcal{F}\{\xv\}$ is precomputed at positions $l \in \mathcal{S}$.
	 			
	 			\item[\color{red} 2.] \textit{\color{blue} Sketch of $\yv$:}  Compute $ \Yv'[l] = \mathcal{F}\{\yv'\}$ for $l \in \mathcal{S}$.
	 			\begin{itemize}
	 				\item[-] Only $M$ non-zero values in $\yv'$ - Efficient computation (folding and adding)
	 			\end{itemize}
	 			
	 			\item[\color{red} 3.] \textit{\color{blue} Sparse $\mathcal{F}^{-1}$}:
	 			\begin{itemize}
	 				\item[-] Robust Sparse Inverse Fourier Transform (RSIDFT)
	 				\item[-] Efficient Implementation- {\color{blue} sublinear} time and sampling complexity
	 			\end{itemize}
	 		\end{itemize}
	 	\end{block}
\end{frame}


%------------------------------------------------------------------
\begin{frame}{Robust Sparse Inverse Fourier Transform(RSIDFT)}
\begin{block}{Main Idea}
	\begin{itemize}
		\item \alert{Sub-sampling} in frequency corresponds to \alert{aliasing} in time
		\item Aliased coefficients $\Leftrightarrow$ parity check constraints of \alert{GLDPC codes}
		\item \alert{CRT} guided sub-sampling induces a code good for \alert{Peeling decoder}
		\item R-FFAST- proposed by Pawar and Ramchandran 2014
	\end{itemize}
\end{block}
\begin{block}{Key modifications}
   \begin{itemize}
   	\item Optimized for the induced noise model
   	\item Correlation peak is always {\color{blue} positive}
   	\item Take advantage in decoding algorithm - {\color{blue}sub-linear} time complexity
   \end{itemize}
\end{block}
\end{frame}

%--------------------------------------------------------------------------------------
	\begin{frame}{Aliasing and Sparse Graph Codes}
		
\only<1>{  \begin{block}{IDFT Computation($N=6$)}
			\begin{figure}[t]
				\centering
				\includegraphics[width=3.1in]{X_DFT}
			\end{figure}
		\end{block}
		
		\begin{columns}
			
			\column{.47\textwidth}
			\begin{block}{{\small $\color{red}x_s$:\ Sub-sampled by $P_1=2$}}
				\begin{figure}[t]
					\centering
					\includegraphics[width=2.3in]{Xs}
				\end{figure}
			\end{block}
			
			\begin{block}{{\small$\color{red}z_s$:\ Sub-sampled by $P_2=3$}}
				\begin{figure}[t]
					\centering
					\includegraphics[width=2.3in]{Zs}
				\end{figure}
			\end{block}
			
			\column{.47\textwidth}
			\begin{block}{\small Factor graph}
				\begin{figure}[t]
					\centering
					\includegraphics[width=2.3in]{Factorgraph_example}
				\end{figure}
			\end{block}
		\end{columns}}

\only<2>{ \begin{block}{IDFT Computation($N=6$)}
		\begin{figure}[t]
			\centering
			\includegraphics[width=3.1in]{X_DFT}
		\end{figure}
	\end{block}
	
	\begin{columns}
		
		\column{.47\textwidth}
		\begin{block}{{\small $\color{red}\tilde{x}_s$:\ Sub-sampled by $P_1=2$ ({\color{blue}shifted})}}
			\begin{figure}[t]
				\centering
				\includegraphics[width=2.3in]{Xs_shift}
			\end{figure}
		\end{block}
		
		\begin{block}{{\small$\color{red}\tilde{z}_s$:\ Sub-sampled by $P_2=3$ ({\color{blue}shifted})}}
			\begin{figure}[t]
				\centering
				\includegraphics[width=2.3in]{Zs_shift}
			\end{figure}
		\end{block}
		
		\column{.47\textwidth}
		\begin{block}{\small Factor graph}
			\begin{figure}[t]
				\centering
				\includegraphics[width=2.3in]{Factorgraph_example_tilde}
			\end{figure}
		\end{block}
	\end{columns}}
		
	\end{frame}

\begin{frame}\frametitle{RSIDFT Framework}
	
		\begin{figure}[t!]
			\begin{center}
				\resizebox{0.8\textwidth}{!}{\input{FFAST_Robust_PM.tex}}
				%	 		\includegraphics[height=7cm]{Figures/FFAST_Robust}
			\end{center}	
			\label{fig:rsidft}
			\vspace{5 pt}
		\end{figure}
\end{frame}


%\begin{frame}\frametitle{RSIDFT Framework}
%	\begin{columns}
%		\column[]{0.43\columnwidth}
%\begin{figure}[t!]
%	\begin{center}
%		\resizebox{1.05\textwidth}{0.7\textheight}{\input{FFAST_Robust_PM.tex}}
%		%	 		\includegraphics[height=7cm]{Figures/FFAST_Robust}
%		\end{center}	
%		\label{fig:rsidft}
%		\vspace{5 pt}
%		\end{figure}
%		\column[]{0.53\columnwidth}
%		\begin{figure}[h!]
%			\begin{center}
%				%		\includegraphics[height=7cm]{Figures/Factorgraph}
%				\resizebox{1.0\textwidth}{0.65\textheight}{\input{Factorgraph_PM.tex}}	
%			\end{center}	
%			%\caption{Example of a Tanner graph formed in a RSIDFT framework with system parameters being $d=2$, $B=2$, $N=6$, $f_1 = 2$ and $f_2=3$. The variable nodes (colored gray circles) represent the cross-correlation vector $\rv$ and the bin nodes (uncolored white boxes) represent the binned observation vector $\zv_{i,k}$. The figure also illustrates the relationship between $\zv_{i,k}$ and $\rv$.}\label{fig:factorgraph}
%			\vspace{5 pt}
%		\end{figure}
%		
%	\end{columns}
%	
%\end{frame}

\begin{frame}\frametitle{RSIDFT-Decoding (Peeling Decoder)}
\begin{columns}
	\column[]{0.65\columnwidth}
		\begin{figure}[h!]
			\begin{center}
				%		\includegraphics[height=7cm]{Figures/Factorgraph}
				\resizebox{1.0\textwidth}{!}{\input{Factorgraph_PM.tex}}	
			\end{center}	
			%\caption{Example of a Tanner graph formed in a RSIDFT framework with system parameters being $d=2$, $B=2$, $N=6$, $f_1 = 2$ and $f_2=3$. The variable nodes (colored gray circles) represent the cross-correlation vector $\rv$ and the bin nodes (uncolored white boxes) represent the binned observation vector $\zv_{i,k}$. The figure also illustrates the relationship between $\zv_{i,k}$ and $\rv$.}\label{fig:factorgraph}
		\end{figure}
	\column[]{0.33\columnwidth}
	    \begin{block}{Observations:}
	          $
	    		\zv_{i,k} = \begin{bmatrix}
	    		r_{i,1}[k]\\
	    		r_{i,2}[k]\\
	    		\vdots\\
	    		r_{i,B}[k]
	    		\end{bmatrix}
	    		$
	    	\end{block}
	    	\begin{block}{Decoding- 3 steps}	
	    		\begin{enumerate}
	    			\item Bin Classification
	    			\item Position Identification
	    			\item Peeling Process
	    		\end{enumerate}
	
	    \end{block}
	
		
\end{columns}	
\end{frame}

\begin{frame}\frametitle{Observations}
\begin{align} \nonumber
	    		\zv_{i,k} = \begin{bmatrix}
	    		r_{i,1}[k]\\
	    		r_{i,2}[k]\\
	    		\vdots\\
	    		r_{i,B}[k]
	    		\end{bmatrix}			
            = \begin{bmatrix}
			1 & 1 & \ldots & 1 \\
			\omega^{k s_2} & \omega^{(k+f_i) s_2} & \ldots & \omega^{(k+(g_i-1)f_i) s_2}   \\
			\vdots & \vdots & \ddots & \vdots\\
			\omega^{k s_B} & \omega^{(k+f_i) s_B} & \ldots & \omega^{(k+(g_i-1)f_i) s_B} \\
			\end{bmatrix} \times
			\begin{bmatrix}
			r[k+(0)f_i] \\
			r[k+(1)f_i] \\
			\vdots\\
			r[k+(g_i-1)f_i]
			\end{bmatrix}
			\end{align}

			\begin{figure}[t]
			\begin{center}
				\includegraphics[width=3.5in]{bin_statistics.png}
			\end{center}
		\end{figure}

\end{frame}

\begin{frame}\frametitle{Decoder}

\only<1>{\begin{block}{Bin Classification}
		\begin{itemize}
			\item  Classify each check-node -  Zero-ton / Single-ton / Multi-ton
			\item  {\color{blue} Threshold constraints} on first observation $z_{i,k}[1] = z$
			\item  Threshold varies with $\eta$
			\begin{itemize}
				\item[-] different for exact($\eta=0$) and approximate matching
			\end{itemize}
		\end{itemize}
		\begin{align}
		\label{Eqn:BinClassifApprox} \nonumber
		\widehat{\mc{H}}_{i,j}=
		\begin{cases}
		\mc{H}_z &  	 z/M < \gamma_1\\
		\mc{H}_s &	  \gamma_1 < z/M < \gamma_2  \\
		\mc{H}_d  &    \gamma_2  < z/M <  \gamma_3\\
		\mc{H}_m &      z/M > \gamma_3\\
		\end{cases}
		\end{align}
		where $(\gamma_1,\gamma_2,\gamma_3)=(\frac{1-2\eta}{2},\frac{3-4\eta}{2},\frac{5-6\eta}{2})$
	\end{block}}
	
\only<2>{\vspace{-5pt} \begin{block}{Position Identification}
		\begin{itemize}
			\item 	{\color{blue}Observation:} 	\begin{align} \nonumber
			\zv_{i,k}= \begin{bmatrix}
			1 & 1 & \ldots & 1 \\
			\omega^{k s_2} & \omega^{(k+f_i) s_2} & \ldots & \omega^{(k+(g_i-1)f_i) s_2}   \\
			\vdots & \vdots & \ddots & \vdots\\
			\omega^{k s_B} & \omega^{(k+f_i) s_B} & \ldots & \omega^{(k+(g_i-1)f_i) s_B} \\
			\end{bmatrix} \times
			\begin{bmatrix}
			r[k+(0)f_i] \\
			r[k+(1)f_i] \\
			\vdots\\
			r[k+(g_i-1)f_i]
			\end{bmatrix}
			\end{align}
			
			\item Column that gives {\color {blue} maximum correlation} with the observation\\
			{ \[\boxed{\hat{k} = \underset{k\in\{j+l f_i\}}{\arg \max}~~ \zv^{\dagger}_{i,j} \mathbf{W}[:,l]}\]}
		\end{itemize}
	
		\end{block}}

\only<3>{ {\Large \alert{Peeling Process:}}
	\begin{columns}
		\column[]{0.35\columnwidth}
	\begin{block}{Exact Matching}
			\begin{itemize}
				\item Remove a decoded variable node's contribution from {\color{blue}all participating bin nodes}
			\end{itemize}
	\end{block}
		\begin{block}{Approximate Matching}
			\begin{itemize}
				\item Remove a decoded variable node's contribution only from neighboring {\color{blue}single-tons and double-tons}
				 \item Avoid error propagation
			\end{itemize}
		\end{block}
		\column[]{0.65\columnwidth}
		\begin{figure}[h!]
			\begin{center}
				%		\includegraphics[height=7cm]{Figures/Factorgraph}
				\resizebox{1\textwidth}{!}{\input{Factorgraph_PM.tex}}	
			\end{center}
		\end{figure}
	\end{columns}}
\end{frame}

\begin{frame}{Error Analysis}
	
	\only<1,3>{\begin{block}{Error Events}
		\begin{itemize}\small
				\item {\color{blue}$\mathcal{E}_1${-\it Bin Classification}}: Bin is wrongly classified
				\item {\color{blue}$\mathcal{E}_2${-\it Pos. Identification}}: Position of singleton is identified wrongly, given a singleton
				\item {\color{blue}$\mathcal{E}_3${-\it Peeling Process}}: Peeling process fails to recover the $L$ significant correlation coefficients, given $\mbb{P}(\mc{E}_1)= \mbb{P}(\mc{E}_2)=0$
		\end{itemize}
	\end{block}
}
	\only<1>{\begin{block}{$\mathcal{E}_1${-\it Bin Classification}}
			\begin{figure}[t]
			\begin{center}
				\includegraphics[width=3.5in]{bin_statistics.png}
			\end{center}
		\end{figure}
		\vspace{-20pt}
		
		{\small \begin{align*}
			\mbb{P}[\mc{E}_1] & \leq & \mbb{P}[\mc{E}_1|\widehat{\mc{H}}_{i,j}=\mc{H}_z]~& + &
			\quad \mbb{P}[\mc{E}_1|\widehat{\mc{H}}_{i,j}=\mc{H}_s]~~~~~& + &
			\quad \mbb{P}[\mc{E}_1|\widehat{\mc{H}}_{i,j}=\mc{H}_d \cup \mc{H}_m]\\
			~& = & \mbb{P}[z[1]>\gamma_1] ~& + & (1- \mbb{P}[\gamma_1<z[1]<\gamma_2])  ~& + & \mbb{P}[z[1]<\gamma_2]~~~~~~
			\end{align*}
		}

			\vspace{-17pt}
	\end{block}
	}
	
	\only<2>{\begin{block}{$\mathcal{E}_2${-\it Pos. Identification}}
			\begin{itemize}
				\item $\underline{z} =  r[j_p] ~ \wv_{j_p}+ \sum_{k \neq p}n_k \wv_{j_k}$
				\item $\mbb{P}[\mc{E}_2] = \mbb{P}[\wv_{j_p}^{\dagger}\underline{z}< \wv_{j_k}^{\dagger}\underline{z}]$
				\item Mutual Incoherence property to bound the cross-correlation(noise) term
				  \begin{itemize}
				  	\item [-] $\log N$ measurements (shifts) suffices [Pawar'14]
				  \end{itemize}
			\end{itemize}
		     \end{block}
		
		\begin{block}{$\mathcal{E}_3${-\it Peeling Process}}
		\begin{itemize}
			\item Tools from Coding Theory to analyze Sparse Graph Codes
			\item Density Evolution to quantify Error Probability
			\item \# of check-nodes is a function of sparsity (query length)
			\item Exponentially decaying error probability- {\small R-FFAST and SAFFRON [Pawar'14, Lee'15]}
		\end{itemize}
		\end{block}
	}	
	
		\only<3>{\begin{block}{Error Probability}
			\begin{align*}
			\mbb{P}(\mathcal{E}_{\text{total}}) & \leq &  \mbb{P}(\mathcal{E}_1)~~~~~ & + & \mbb{P}(\mc{E}_2)~~~~~~~~ & + & \mbb{P}(\mc{E}_3)~~~~~~~~\\
			&\leq & 6e^{-\frac{N^{\mu+\alpha-1}(1-6\eta)^2}{16}}~ & + & 2e^{-N^{\mu+\alpha-1} ~ c_1(\eta)}~ & + &  e^{-c_3 N^{c_4\alpha}}
			\end{align*}
			\[\boxed{	\mbb{P}(\mathcal{E}_{\text{total}}) \rightarrow 0  ~~\text{if}~~  \alpha >1-\mu}\]
		\end{block}
	     }	
\end{frame}

\begin{frame}{Complexity Analysis}
	\begin{block}{Sample Complexity}
		\vspace{-10pt}
		\begin{align*}
		\text{Total \# of samples required (S)} &= O \left(dBN^{\alpha}\right) =   {\color{blue}O(N^{1-\mu}\log N)}
		\end{align*}
		
	\end{block}
	\begin{block}{Computational Complexity}
		\begin{equation*}\label{eqn:Rxy_fourier}
		\rv = \underset{\color{red}  \RNum{2} } {\mathcal{F}_{N}^{-1}} \ \{   \mathcal{F}_{N}\{\xv\}  \odot \ \underset{\color{red}  \RNum{1}  }{ \mathcal{F}_{N}\{\yv'\}}  \}
		\end{equation*}
		\vspace{-10pt}
	\begin{itemize}
		\item {\color{blue}Sketch of Query:}\\ \vspace{5pt}
	 {\small $C_{\color{red}\RNum{1}} \ = \  dB ~
	 ( \underset{\text{Folding} }{\underbrace{N^{\mu}}} + \ \
	 \underset{\text{Shorter FFTs} }{\underbrace{N^{\alpha} \ \log N^{\alpha}}} \ )
	 =  {\color{blue} O(\max(N^{1-\mu}\log^2 N ,N^{\mu}\log N)) }$}

		\item {\color{blue}RSIDFT:} \\	{\small$C_{\color{red} \RNum{2}} =  {d B}  \left (
			\underset{\text{Shorter IFFTs /block/stage} }{\underbrace{ O(N^{\alpha}  \log N^{\alpha})}} \hspace{-3pt}+ \underset{\text{Correlations} }{\underbrace{ L~N^{1-\alpha}}} \right ) = {\color{blue} O(\max(N^{1-\mu}\log^2 N ,N^{\mu+\lambda}\log N)) }$}
	\end{itemize}
	\vspace{10pt}	
	\[\boxed{C_{\text{total}} = \max(C_{\color{red} \text{ \RNum{1}}},C_{\color{red} \text{ \RNum{2}}}) = {\color{blue} O(\max(N^{1-\mu}\log^2 N ,N^{\mu+\lambda}\log N)) }}\]
		
	\end{block}
\end{frame}

\begin{frame}\frametitle{Simulation Results}
\only<1>{\begin{figure}[h!]
		\begin{center}
			
			\resizebox{0.7\textwidth}{!}{\input{sim_results_M_10_7.tex}}	
				\end{center}
			\caption{Plot of Probability of Missing a Match vs. Sample Gain for Exact Matching of a substring of length $M=10^5$($\mu=0.41$) from a equiprobable  binary \{+1,-1\} sequence of length $N= 10^{12}$, divided into $G=10^{5}$ blocks each of length $\tilde{N}=10^7$. The substring was simulated to repeat in $L=10^6$($\lambda=0.5$) locations uniformly at random.}
	
\end{figure}}

\only<2>{\begin{figure}[h!]
	\begin{center}
		\resizebox{0.7\textwidth}{!}{\input{sim_results_M_10_3.tex}}	
	\end{center}
	\caption{Plot of Probability of Missing a Match vs. Sample Gain for Exact Matching of a substring of length $M=10^3$($\mu=0.25$) from a equiprobable  binary \{+1,-1\} sequence of length $N= 10^{12}$, divided into $G=10^{6}$ blocks each of length $\tilde{N}=10^6$. The substring was simulated to repeat in $L=10^6$($\lambda=0.5$) locations uniformly at random.}
	
\end{figure}}

\end{frame}	






