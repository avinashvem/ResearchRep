
\label{section:background}

In this section, we briefly describe the WZ and GP side-information problems, and a coding scheme that achieves the rate regions of these problems.
We closely follow the formulation in \cite{Wainwright-it09}.
\subsection{Side-Information Problems}

\subsubsection{Rate Distortion with Side Information}
Consider a linear code $\mathcal{C} \subset \{0,1\}^n$ with rate $R=k/n$ and an iid sequence $X^n = (X_1,\ldots,X_n) \in \{0,1 \}^n$, where each $X_i$ is $\mathsf{Ber}(\tfrac{1}{2})$ and $\mathsf{Ber}(\delta)$ denotes a Bernoulli random variable with parameter $\delta$.
In the rate distortion problem, the objective is to optimally encode $X^n$ to some codeword $\wh{X}^n \in \mathcal{C}$ so as to minimize the average normalized Hamming distortion $D$ between $X^n$ and $\wh{X}^n$, $D=\frac{1}{n} \sum_{i=1}^n \expt |X_i - \wh{X}_i|$.
For this problem, Shannon's rate-distortion theory \cite{Cover-2006} shows that any rate $R > 1 - h(D)$ is achievable, where $h(\cdot)$ is the binary entropy function.
Since $R \geq 1 - h(D)$ is also necessary, roughly $n(1-h(D))$ bits are required to specify $X^n$ up to normalized distortion $D$.

In the WZ formulation of the rate distortion problem, there is side information $Z^n$ at the decoder about $X^n$.
Suppose the side information $Z^n$ takes the form $Z_i = X_i \oplus \mathsf{Ber}(\delta)$, where $\oplus$ denotes addition modulo $2$.
Then, \cite{Wyner-it76} shows that any rate,
\begin{align}
  \label{equation:wz_rate}
  R > R_{WZ}(D,\delta) = l.c.e \{ h(D * \delta) - h(D) , (\delta,0) \},
\end{align}
where $D*\delta=D(1-\delta)+\delta(1-D)$, is achievable, to describe $X^n$ (up to normalized distortion $D$) along with side information $Z^n$.
In (\ref{equation:wz_rate}), $l.c.e$ denotes the lower convex envelope.

\subsubsection{Channel Coding with Side Information}
Suppose again that $\mathcal{C} \subset \{0,1\}^n$ is a linear code with rate $R=k/n$ and that $W^n \in \{0,1\}^n$ is distributed iid according to $\mathsf{Ber}(\delta)$.
In the channel coding problem, the objective is to encode a message $m^k \in \{0,1\}^{k}$ into a codeword $X^n \in \mathcal{C}$ so that the decoder can reliably estimate the message $m^k$ from the decoder output $X^n \oplus W^n$.
%When the channel $\{W_i\}$ is distributed iid according to $\mathsf{Ber}(\delta)$, classical result in information theory states that any rate $R < 1 - h(\delta)$ is both necessary and sufficient.
In the GP formulation, the output at the receiver is given by $Y^n = X^n \oplus Z^n \oplus W^n$, where the side information $Z^n \in \{0,1\}^n$ is available a priori to the encoder but not the decoder.
Additionally, the average weight of the codeword $X^n$ is required to satisfy $\frac{1}{n} \sum_{i=1}^n \expt [X_i] \leq p$,  $\delta < p \leq \tfrac{1}{2}$. 

% Additionally, the average weight of the codeword $X^n$ is required to satisfy
% \begin{align*}
%   \frac{1}{n} \sum_{i=1}^n \expt [X_i] &\leq p, & \delta < p &\leq \tfrac{1}{2} . 
% \end{align*}
Under these conditions, \cite{Gelfand-ppi80} shows that the rate constraint
\begin{align}
  \label{equation:gp_rate}
  R < R_{GP}(p,\delta)=h(p) - h(\delta)
\end{align}
is both necessary and sufficient.

\subsection{Coding Scheme via Compound LDGM/LDPC Codes}

\begin{figure}[!t]
  \centering
  \setlength\tikzheight{5cm}
  \setlength\tikzwidth{6cm}
  \scalebox{0.8}{\input{./Figures/compound_code}}
  \vspace{-2.5mm}
  \caption{The Tanner graph representation of a compound LDGM/LDPC code.
  }
  \label{figure:tanner_graph_compound_code}
\end{figure}
We now describe coding schemes for the above side-information problems that achieve the rate regions in (\ref{equation:wz_rate}) and (\ref{equation:gp_rate}) under optimal encoding and decoding.
The emphasis here is not on the practical nature of the encoding or decoding technique.
In the next section, we modify the coding scheme presented here to have efficient encoding and decoding algorithms that appear to achieve the rate regions (\ref{equation:wz_rate}) and (\ref{equation:gp_rate}).

At the heart of these coding schemes is a compound LDGM/LDPC code \cite{Hsu-it10}, \cite{MacKay-elet96}, \cite{Wainwright-it09}.
We illustrate these codes through an example.
The upper portion of the Tanner graph in Fig.~\ref{figure:tanner_graph_compound_code} represents a length-$n$ LDGM code with information bit length $m$, where the codeword is $x^n=(x_1,\ldots,x_n) \in \{0,1\}^n$ and the information bits are $(u_1,\ldots,u_m) \in \{0,1\}^m$.
In the compound code, additionally, the information bits are required to satisfy certain parity constraints.
These constraints are split into two groups $\mathcal{P}_1$ and $\mathcal{P}_2$ with $|\mathcal{P}_1|=k$ and $|\mathcal{P}_2|=k'$.
The parities in $\mathcal{P}_1$ specify a fixed constraint given by $s^k=(s_1,\ldots,s_k) \in \{0,1\}^k$.
For the example in Fig.~\ref{figure:tanner_graph_compound_code}, this means $u_1 \oplus u_2 \oplus u_5=s_1$ and $u_3 \oplus u_4 \oplus u_5=s_2$.
The parities in group $\mathcal{P}_2$ are the usual even parities and for the example, $u_1 \oplus u_3 \oplus u_6=0$, $u_2 \oplus u_4 \oplus u_6=0$.
The bottom part therefore represents constraints akin to an LDPC code.
As such, these codes are referred to as compound LDGM/LDPC codes.
We distinguish between LDGM and LDPC check-nodes and we refer to the nodes representing $x_i$'s as LDGM bit-nodes and $u_i$'s as LDPC bit-nodes.
The codebook is the set of all sequences $x^n$ generated by the LDPC bit-nodes that satisfy the required constraints.

A few observations are in order.
We note that the design rate of this code is $\tfrac{m-k-k'}{n}$.
% We note that the design rate of this code is 
% \begin{align*}
%   \frac{m-k-k'}{n} = \frac{d_c}{d_v}\left(1- \frac{d'_v}{d'_c}\right)
% \end{align*}
The codebook specified by a compound code is linear if and only if the parity constraints in $\mathcal{P}_1$ satisfy $s^k=0^k$.
There is also a natural coset decomposition of these codes.
Ignore for a moment the parity constraints specified by $\mathcal{P}_1$, and denote the resulting linear code by $\mathcal{C}$.
Denote by $\mathcal{C}(s^k)$, the original codebook when the parities in $\mathcal{P}_1$ satisfy $s^k \in \{0,1\}^k$.
It is easy to see that $\mathcal{C} = \bigcup_{s^k \in \{0,1\}^k} \mathcal{C}(s^k)$.

Now, we describe another codebook $\mathcal{C}'$ that is of interest for the WZ problem.
The codebook $\mathcal{C}'$ is obtained from $\mathcal{C}$ by ignoring all the constraints in $\mathcal{P}_2$.
In particular, $\mathcal{C}'$ is the linear code generated from the LDGM part of $\mathcal{C}$.
In describing $\mathcal{C}$, the constraints in $\mathcal{P}_1$ are not active.
When the constraints in $\mathcal{P}_1$ are active, the codebook generated by ignoring $\mathcal{P}_2$ is denoted by $\mathcal{C}'(s^k)$.
Note that $\mathcal{C}'(s^k)$ is a compound code in itself (with an empty $\mathcal{P}_2$).
We again have the coset decomposition of $\mathcal{C}'$ into $\mathcal{C}'(s^k)$.
% \begin{align*}
%   \mathcal{C}' = \bigcup_{s^k \in \{0,1\}^k} \mathcal{C}'(s^k) .
% \end{align*}

The main attraction of the compound codes is that they are simultaneously good for rate distortion and channel coding.
In this article, we use the term \emph{good} to mean the following.
\begin{remark}
  We call a code ``good for rate distortion'' if the design rate of the code satisfies $R=1-h(D)+\varepsilon$ for a small $\varepsilon$ and, when the code is used to optimally encode a $\mathsf{Ber}(\tfrac{1}{2})$ sequence, the average normalized Hamming distortion is at most $D$.
  Similarly, we call a code ``good for channel coding'' if $R=1-h(\delta) - \varepsilon$ and, when the code is used for the channel coding problem with the channel $\mathsf{Ber}(\delta)$, the message can be reliably estimated under optimal decoding with probability of error at most $\varepsilon$.
\end{remark}

We know that the codebooks $\mathcal{C}$, $\mathcal{C}(s^k)$, $\mathcal{C}'(s^k)$ are good for both rate distortion and channel coding for any $s^k \in \{0,1\}^k$ \cite{Wainwright-it09}.
But $\mathcal{C}'$ is not a good channel code, since LDGM codes with fixed degrees exhibit non-negligible error floors.
However, $\mathcal{C}'$ is good for rate distortion \cite{Wainwright-it10}.

Below, we describe coding schemes for our side-information problems, using the codebooks $\mathcal{C}$, $\mathcal{C}'$, $\mathcal{C}(S)$, $\mathcal{C}'(S)$.
That these schemes achieve the rate regions in (\ref{equation:wz_rate}) and (\ref{equation:gp_rate}) will be an immediate consequence of the fact that compound codes are simultaneously good for rate distortion and channel coding, and LDGM codes are good for rate distortion.
We only make heuristic arguments in the following, but these can easily be made rigorous.

\subsubsection{Coding Scheme for Wyner-Ziv}
For small $\varepsilon>0$, choose $n$, $m$, $k$ such that
\begin{align*}
  \frac{m}{n} &= 1 - h(D) + \varepsilon/2, & \frac{k}{n}&=h(D*\delta) - h(D) + \varepsilon.
\end{align*}
Consider a compound code with block length $n$, information bit length $m$, $|\mathcal{P}_1|=k$ and $|\mathcal{P}_2|=0$ such that $\mathcal{C}'$ is a good rate distortion code with rate $m/n$ and $\mathcal{C}'(s^k)$ is a good channel code with rate $1-h(D*\delta) - \varepsilon/2$.

Suppose we want to encode $X^n \in \{0,1\}^n$ up to normalized distortion $D$, with side information $Z^n$ in the form $Z_i = X_i \oplus \mathsf{Ber}(\delta)$.
The sequence $X^n$ can be encoded to $\wh{X}^n \in \mathcal{C}'$ with distortion at most $D$, since $\mathcal{C}'$ is a good rate distortion code.
The sequence $\wh{X}^n$ belongs to a unique coset $\mathcal{C}'(\wh{s^k})$ for some $\wh{s^k} \in \{0,1\}^k$.
The encoder transmits $\wh{s^k}$ to the decoder, which requires a rate of $  R = \frac{k}{n} = h(D*\delta) - h(D) + \varepsilon$.

The decoder, together with side information $Z^n$ and $\wh{s^k}$, tries to recover $\wh{X}^n$.
Note that
\begin{align*}
  Z_i &= X_i \oplus \mathsf{Ber}(\delta), \quad \text{and}  & \frac{1}{n} \sum_{i=1}^n \expt |X_i-\wh{X}_i| \approx D .
\end{align*}
This however implies $Z_i \approx \wh{X}_i \oplus \mathsf{Ber}(D * \delta)$ .
Since $\mathcal{C}'(\wh{s^k})$ is a good channel code with rate $1 - h(D*\delta) - \varepsilon/2$, the decoder can recover $\wh{X}^n$ reliably.
As such, any rate $R > h(D*\delta) - h(D)$ is sufficient to describe $X$ up to distortion $D$.
Thus, the rate region in (\ref{equation:wz_rate}) is achievable with this scheme.

\begin{remark}
  The coding scheme we described above is slightly different from \cite{Wainwright-it09}.
  The difference is in using $\mathcal{C}'$ instead of $\mathcal{C}$ when compressing $X^n$ to $\wh{X}^n$.
  The reason for our choice will be apparent later.
\end{remark}

\subsubsection{Coding Scheme for Gelfand-Pinsker}
First, choose $n$, $m$, $k$, $k'$ such that
\begin{align*}
  \frac{m-k'}{n} &= 1 - h(\delta) - \varepsilon/2, & \frac{m-k-k'}{n} &= 1 - h(p) + \varepsilon/2 .
\end{align*}
Consider a compound code with parameters $n$, $m$, $k$, $k'$ such that $\mathcal{C}$ is a good channel code with rate $\tfrac{m-k'}{n}$ and $\mathcal{C}(s^k)$ is a good rate distortion code with rate $\tfrac{m-k-k'}{n}$.

We want to transmit a message $m^k \in \{0,1\}^k$, when the encoder has side information $Z^n$.
First, at the encoder, the side information $Z^n$ is compressed to $\wh{Z}^n \in \mathcal{C}(m^k)$.
Since $\mathcal{C}(m^k)$ is a good rate distortion code with rate $1 - h(p) + \varepsilon/2$, we have
\begin{align*}
  \frac{1}{n} \sum_{i=1}^n \expt |Z_i -\wh{Z}_i| \approx p, \quad \text{or} \quad \wh{Z}_i \approx Z_i \oplus \mathsf{Ber}(p) . 
\end{align*}
The encoder transmits the vector $X^n = \wh{Z}^n \oplus Z^n$.
It is important to note that this choice of $X^n$ has an average weight of $p$.
The output at the decoder is given by $Y^n = X^n \oplus Z^n \oplus W^n = \wh{Z}^n \oplus W^n$, where the channel $W^n$ is distributed iid according to $\mathsf{Ber}(\delta)$.
Since $\mathcal{C}$ is a good channel code with rate $1-h(\delta) -\varepsilon/2$, $\wh{Z}^n$ can be reliably decoded at the receiver.
Now, since $\wh{Z}^n$ belongs to a unique coset $\mathcal{C}(m^k)$, the message $m^k$ can be recovered reliably.
Thus, any rate $R=k/n<h(p)-h(\delta)$ is achievable.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "isit14"
%%% End: 
